{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP6/XgyUkPF4wDy3i5SqAU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacopooOrsinii/Project2_LSTM_for_reviews/blob/main/Project2_LSTM_for_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2: LSTM for reviews"
      ],
      "metadata": {
        "id": "9WE2zStzWLOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project I aim to implement 3 forms of embeddings (Word2Vec, festtext and glove) to combine them to train a classifier, in particular a version of the LSTM will be implemented. The goal of the analysis is to classify positive (3-4-5 stars) and negative (1-2 stars) reviews based on the review content."
      ],
      "metadata": {
        "id": "upN3kNHVYwUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Loading the necessary packages and files"
      ],
      "metadata": {
        "id": "nUSLpxJXWUzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this first part of the first Task we are going to download all the packages required to implement all the tasks. From the website https://amazon-reviews-2023.github.io/ we can donload different datasets related to amazon products, divided according to the category they refer to. In this case, I decided to work on the dataset related to the Gift cards."
      ],
      "metadata": {
        "id": "qegnFg-HZkEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quiet \"pandas\" \"ipython[notebook]\" \"torchvision\" \"setuptools==59.5.0\" \"torch>=1.8\" \"torchmetrics>=0.7\" \"seaborn\" \"pytorch-lightning>=1.4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTq1MfoWWbcn",
        "outputId": "220d4752-05c1-416d-a25a-db58808f01bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.18.0 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import gzip\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81XmRjsyWeOH",
        "outputId": "64c07863-fa85-41d0-cccf-0d307d718af4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Gift_Card file is downloaded from the related link\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/review_categories/Gift_Cards.jsonl.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_c9U-W0WiAo",
        "outputId": "eb31919a-4947-4551-9c81-6771d6fc05e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-19 15:58:33--  https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/review_categories/Gift_Cards.jsonl.gz\n",
            "Resolving datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)... 132.239.8.30\n",
            "Connecting to datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)|132.239.8.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12556849 (12M) [application/x-gzip]\n",
            "Saving to: ‘Gift_Cards.jsonl.gz’\n",
            "\n",
            "Gift_Cards.jsonl.gz 100%[===================>]  11.97M  2.60MB/s    in 4.6s    \n",
            "\n",
            "2024-08-19 15:58:38 (2.60 MB/s) - ‘Gift_Cards.jsonl.gz’ saved [12556849/12556849]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The file names are defined\n",
        "gz_file_name = \"Gift_Cards.jsonl.gz\"\n",
        "jsonl_file_name = \"Gift_Cards.jsonl\"\n",
        "\n",
        "# With this code the .gz file existence is checked and later on, the .gz file is decompressed\n",
        "if os.path.exists(gz_file_name):\n",
        "\n",
        "    with gzip.open(gz_file_name, 'rt', encoding='utf-8') as gz_file:\n",
        "        with open(jsonl_file_name, 'w') as jsonl_file:\n",
        "            jsonl_file.write(gz_file.read())\n",
        "\n",
        "# With this code we verify if the decompressed file exists\n",
        "if os.path.exists(jsonl_file_name):\n",
        "    # Here a small function to display in a nice way the JSON file is created\n",
        "    def pprint(x):\n",
        "        print(json.dumps(x, indent=2)) if isinstance(x, dict) else display(x)\n",
        "\n",
        "    # Wit this code the first element from the JSONL file is read and pretty print\n",
        "    with open(jsonl_file_name, 'r') as fp:\n",
        "        for line in fp:\n",
        "            pprint(json.loads(line.strip()))\n",
        "            break\n",
        "\n",
        "    # Loading of the JSONL file into a pandas DataFrame\n",
        "    df = pd.read_json(jsonl_file_name, lines=True)\n",
        "\n",
        "    # Display the DataFrame\n",
        "    df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzVd0r6IWkbp",
        "outputId": "ab8a6388-50cb-4bcf-f6ea-84e4933e1c7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"rating\": 5.0,\n",
            "  \"title\": \"Great gift\",\n",
            "  \"text\": \"Having Amazon money is always good.\",\n",
            "  \"images\": [],\n",
            "  \"asin\": \"B00IX1I3G6\",\n",
            "  \"parent_asin\": \"B00IX1I3G6\",\n",
            "  \"user_id\": \"AHZ6XMOLEWA67S3TX7IWEXXGWSOA\",\n",
            "  \"timestamp\": 1549866158332,\n",
            "  \"helpful_vote\": 0,\n",
            "  \"verified_purchase\": true\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our DataFrame is displayed after removing all the column apart from the text column and the rating column which will be fundamental for the implementation of the LSTM model."
      ],
      "metadata": {
        "id": "dTSfW2KJaT6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['text','rating']]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Q6gZR4LpWpDY",
        "outputId": "92689393-0377-4960-e586-36a01e788bba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  rating\n",
              "0                     Having Amazon money is always good.       5\n",
              "1       Always the perfect gift.  I have never given o...       5\n",
              "2       When you have a person who is hard to shop for...       5\n",
              "3       The tin is a nice touch and pretty large.  It'...       5\n",
              "4       I bought this pack of Starbucks Gift cards in ...       1\n",
              "...                                                   ...     ...\n",
              "152405  I was really impressed with the pink bag.  I g...       5\n",
              "152406  Realmente es fascinante como hacen de algo muc...       5\n",
              "152407                                  Hit  accidentally       1\n",
              "152408                                              Great       5\n",
              "152409                                           muy bien       4\n",
              "\n",
              "[152410 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6facf189-3461-456a-b76e-ff131c5bd472\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Having Amazon money is always good.</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Always the perfect gift.  I have never given o...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When you have a person who is hard to shop for...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The tin is a nice touch and pretty large.  It'...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I bought this pack of Starbucks Gift cards in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152405</th>\n",
              "      <td>I was really impressed with the pink bag.  I g...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152406</th>\n",
              "      <td>Realmente es fascinante como hacen de algo muc...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152407</th>\n",
              "      <td>Hit  accidentally</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152408</th>\n",
              "      <td>Great</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152409</th>\n",
              "      <td>muy bien</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152410 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6facf189-3461-456a-b76e-ff131c5bd472')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6facf189-3461-456a-b76e-ff131c5bd472 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6facf189-3461-456a-b76e-ff131c5bd472');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-158a5151-0ac7-4daa-9868-1ae1006a46e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-158a5151-0ac7-4daa-9868-1ae1006a46e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-158a5151-0ac7-4daa-9868-1ae1006a46e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f99861d7-2a50-46bf-8a59-c1df2e919873\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f99861d7-2a50-46bf-8a59-c1df2e919873 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocessing of the reviews"
      ],
      "metadata": {
        "id": "6yelJNNfXgyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part of the Task we preprocess the reviews in order to clear them and have them ready to be passed inside the model. \\\n",
        "In particular the preprocessing steps we made are: \\\n",
        "- Tokenization: the input text is split into singular tokens\n",
        "- Lowering: all the tokens are converted into lower case\n",
        "- Removal of stopwords: the common english stopwords are filtered \\\n",
        "\n",
        "The output of this code will give us back the reviews cleaned."
      ],
      "metadata": {
        "id": "8uN1DVxUafOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    # Lowering and number/charaters removal\n",
        "    cleaned_tokens = [token.lower() for token in tokens if token.isalpha()]\n",
        "    # Removal of stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in cleaned_tokens if token not in stop_words]\n",
        "\n",
        "    return filtered_tokens\n",
        "\n",
        "# The preprocessing function is applied to the column \"text\" of the DataFrame df\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# The column \"text\" is saved into the variable x\n",
        "x = df[\"text\"].to_numpy()"
      ],
      "metadata": {
        "id": "Gzb98OPUXokk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Embeddings"
      ],
      "metadata": {
        "id": "2RrQhdIFYHI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word embeddings are at the base of our Task, they allow us to associate each word with a vector of numbers in order to have words with similar meanings mapped to similar vectors. In particular, we are going to implement 3 kinds of word embeddings that are: \\\n",
        "- Word2Vec\n",
        "- Fasttext\n",
        "- Glove"
      ],
      "metadata": {
        "id": "tKLuJ6pSanfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We download the glove.6B.zip file from the related link\n",
        "!wget nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "# We unzip the glove.6B.zip file\n",
        "!unzip glove*.zip\n",
        "\n",
        "# With this line of code we implement Word2vec\n",
        "model1 = Word2Vec(x, min_count = 1, vector_size = 100, window = 3)\n",
        "\n",
        "# With this line of code we imlement Festtext\n",
        "ft_model = FastText(sentences=x, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# With this code we implement Glove\n",
        "glove_vectors = {}\n",
        "with open('glove.6B.100d.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_vectors[word] = vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIfM19FSYK9q",
        "outputId": "282458e1-9d75-4a92-ab57-729af420215e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-19 16:03:30--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-08-19 16:03:30--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-08-19 16:03:30--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.15MB/s    in 2m 40s  \n",
            "\n",
            "2024-08-19 16:06:10 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Combining the embeddings"
      ],
      "metadata": {
        "id": "utVQ1qL4bFgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the 3 types of embedding and we want to concatenate them in a vector that will contain 300 numbers, 100 for each embedding we implemented. Before doing this, we create a list of unique words that contains 22.620 items; in this way we will have a dictionary that will have a list of 300 numbers associated to each unique word."
      ],
      "metadata": {
        "id": "H_PhON5_bjs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a list of unique words among all the reviews we have\n",
        "all_tokens = [token for sublist in df['text'] for token in sublist]\n",
        "unique_words = list(set(all_tokens))\n",
        "print(len(unique_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qy-uZsTbLli",
        "outputId": "0dd5b2b3-230b-4140-964e-9a70cab0718f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The concatenated_arrays list and word_vectors dictionary are initialised\n",
        "concatenated_arrays = []\n",
        "word_vectors = {}\n",
        "\n",
        "# This code iterates over all the unique words and checks if it exists in the 3 models, eventually if a word doesn't exist in one of the 3 models,\n",
        "# Then the missing space is fulifilled with 0s\n",
        "for word in unique_words:\n",
        "    model1_array = model1.wv[word] if word in model1.wv else np.zeros(100)\n",
        "    ft_array = ft_model.wv[word] if word in ft_model.wv else np.zeros(100)\n",
        "    glove_array = glove_vectors[word] if word in glove_vectors else np.zeros(100)\n",
        "\n",
        "    # The 3 embeddings are concatenated and stored into the dictionary word_vector, with the word as key\n",
        "    concatenated_array = np.concatenate((model1_array, ft_array, glove_array))\n",
        "    concatenated_arrays.append(concatenated_array)\n",
        "    word_vectors[word] = concatenated_array\n",
        "\n",
        "# The list of concatenated arrays is converted to a numpy array\n",
        "concatenated_arrays = np.array(concatenated_arrays)\n",
        "\n",
        "print(\"Length of unique words list:\", len(unique_words))\n",
        "print(\"Length of concatenated arrays list:\", len(concatenated_arrays))\n",
        "print(\"Shape of concatenated arrays:\", concatenated_arrays.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKTdukmFbb6Y",
        "outputId": "35f19221-4094-4ab0-b307-656c0086be10"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of unique words list: 22620\n",
            "Length of concatenated arrays list: 22620\n",
            "Shape of concatenated arrays: (22620, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code shows the output of the concatenation for the word \"good\"\n",
        "if \"good\" in word_vectors:\n",
        "    good_vector = word_vectors[\"good\"]\n",
        "    print(\"Vector for 'good':\", good_vector)\n",
        "    print(\"Length of the vector for 'good':\", len(good_vector))\n",
        "else:\n",
        "    print(\"The word 'good' is not in the vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c7rlddMbgZW",
        "outputId": "ff0dbc43-ba61-45d8-9e2a-f343b571993f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'good': [ 1.11308195e-01  6.61550522e-01  1.27964735e+00 -1.82640147e+00\n",
            " -4.39319685e-02 -8.38912964e-01  1.71587169e-01  1.44433737e+00\n",
            "  5.42492807e-01 -1.52923810e+00  1.11810374e+00 -9.43678081e-01\n",
            " -5.31572253e-02 -1.51736736e+00  5.68542182e-01  7.29231298e-01\n",
            "  1.36784685e+00  2.49007791e-01  4.08468604e-01 -4.11906034e-01\n",
            " -6.67311549e-01 -3.78232270e-01  1.17556965e+00 -3.65419805e-01\n",
            " -1.22896051e+00  1.35623419e+00  1.92432702e-01 -2.43217409e-01\n",
            "  5.61058939e-01  8.80863369e-01  2.90771782e-01 -6.83722317e-01\n",
            " -2.04461798e-01 -7.21382499e-01  1.13299154e-02  8.13666344e-01\n",
            "  9.29577589e-01 -2.00423095e-02 -9.05989707e-01 -8.43428671e-01\n",
            "  1.05877137e+00 -3.61342967e-01 -2.91185051e-01  5.01345634e-01\n",
            "  4.43044245e-01  1.73339099e-01  4.46950406e-01 -9.48733330e-01\n",
            " -4.91344362e-01  5.01725376e-01  3.03299963e-01  1.15454614e-01\n",
            " -2.60206342e-01 -2.57453948e-01  5.32306265e-03 -1.10327907e-01\n",
            " -1.65504634e-01  9.12288606e-01  3.52848947e-01 -7.50020817e-02\n",
            " -7.10918725e-01 -3.57042640e-01  6.19148076e-01  4.94036138e-01\n",
            " -2.07241580e-01 -2.09993087e-02 -3.79075676e-01 -4.26356234e-02\n",
            " -1.61175206e-01 -2.11529195e-01  2.70760705e-04 -1.42908946e-01\n",
            "  1.84861924e-02  9.85163689e-01  2.44473055e-01  2.26754293e-01\n",
            "  2.01788202e-01  7.72849470e-03 -9.75892782e-01  2.95548707e-01\n",
            " -1.03439140e+00  1.35645604e+00 -4.28825505e-02  2.78118134e-01\n",
            " -9.80896354e-01 -5.78010082e-01  4.85483706e-01  6.61714315e-01\n",
            " -2.95796841e-01 -5.10048568e-01  1.02255785e+00  6.79457903e-01\n",
            " -1.78303480e-01  6.12932980e-01  8.11081588e-01 -2.20085070e-01\n",
            " -4.13868368e-01 -4.47374061e-02 -3.10839951e-01 -5.27253568e-01\n",
            "  4.87109393e-01 -7.15132952e-01  5.60672700e-01  1.01020662e-02\n",
            " -1.31023183e-01 -1.33309454e-01 -3.11129332e-01  2.80547595e+00\n",
            "  3.38159502e-01  1.36462605e+00  3.22094619e-01  1.29165217e-01\n",
            " -4.57695186e-01  1.34719312e+00  9.19254720e-01  1.23860753e+00\n",
            "  1.20069647e+00 -1.63917553e+00  1.19048381e+00 -2.62225419e-01\n",
            " -8.49430323e-01  3.75879645e-01  4.60620046e-01  7.71231234e-01\n",
            " -2.81702161e+00 -3.09008628e-01  2.23966584e-01  1.06100690e+00\n",
            "  7.40601540e-01  1.23443651e+00 -4.60413694e-02 -1.40036345e+00\n",
            "  6.39343500e-01  4.55392838e-01 -4.85352390e-02  1.04016316e+00\n",
            "  1.34148920e+00 -1.56890869e-01  3.56862515e-01 -5.31517267e-01\n",
            "  1.23847592e+00  1.40183344e-01  6.82614326e-01  1.20397842e+00\n",
            "  1.41556039e-01 -7.97017515e-02  2.03616425e-01 -1.50792539e-01\n",
            "  2.29659751e-01  1.46640792e-01  4.35208887e-01 -2.13043973e-01\n",
            "  3.09069544e-01 -1.67033851e+00 -2.74342060e-01 -2.05599114e-01\n",
            "  6.10260248e-01  2.96975166e-01  1.44915414e+00 -2.13469315e+00\n",
            " -2.07442418e-01 -6.39586896e-02 -1.14278877e+00  6.87903106e-01\n",
            "  2.82097042e-01  5.93502104e-01  4.60818261e-01  2.74997205e-01\n",
            " -4.02279407e-01  1.00512743e-01  6.74101990e-03  5.48950434e-01\n",
            " -3.30774337e-02  1.56335652e+00 -1.10621285e+00 -6.19099140e-01\n",
            " -3.76776397e-01 -3.11356783e-01 -1.62880409e+00 -1.21017456e+00\n",
            " -1.35433972e+00 -5.68310559e-01  5.79623938e-01 -4.11664933e-01\n",
            "  1.09177721e+00 -1.17939305e+00 -1.11241035e-01 -1.22225857e+00\n",
            " -2.17061087e-01 -1.32423127e+00 -6.78870142e-01 -3.14004731e+00\n",
            "  8.50348473e-01  1.13303530e+00 -4.38880831e-01  1.41390324e+00\n",
            "  2.29607487e+00  1.15531743e+00  1.57298577e+00  6.54826701e-01\n",
            " -3.07689998e-02  1.19929999e-01  5.39089978e-01 -4.36960012e-01\n",
            " -7.39369988e-01 -1.53449997e-01  8.11259970e-02 -3.85589987e-01\n",
            " -6.87969983e-01 -4.16319996e-01 -1.31830007e-01 -2.49219999e-01\n",
            "  4.41000015e-01  8.59190002e-02  2.08710000e-01 -6.35820031e-02\n",
            "  6.22280017e-02 -5.12339994e-02 -1.33980006e-01  1.14180005e+00\n",
            "  3.65259983e-02  4.90289986e-01 -2.45670006e-01 -4.12000000e-01\n",
            "  1.23489998e-01  4.13360000e-01 -4.83969986e-01 -5.42429984e-01\n",
            " -2.77869999e-01 -2.60149986e-01 -3.84849995e-01  7.86559999e-01\n",
            "  1.02300003e-01 -2.07120001e-01  4.07510012e-01  3.20259988e-01\n",
            " -5.10519981e-01  4.83619988e-01 -9.94979963e-03 -3.86849999e-01\n",
            "  3.49749997e-02 -1.66999996e-01  4.23700005e-01 -5.41639984e-01\n",
            " -3.03229988e-01 -3.69830012e-01  8.28360021e-02 -5.25380015e-01\n",
            " -6.45309985e-02 -1.39800000e+00 -1.48729995e-01 -3.53269994e-01\n",
            " -1.11800000e-01  1.09119999e+00  9.58639979e-02 -2.81290007e+00\n",
            "  4.52380002e-01  4.62130010e-01  1.60119998e+00 -2.08370000e-01\n",
            " -2.73770005e-01  7.11969972e-01 -1.07539999e+00 -4.69739996e-02\n",
            "  6.74790025e-01 -6.58390000e-02  7.58239985e-01  3.94050002e-01\n",
            "  1.55070007e-01 -6.47189975e-01  3.27960014e-01 -3.17480005e-02\n",
            "  5.28989971e-01 -4.38859999e-01  6.74049973e-01  4.21359986e-01\n",
            " -1.19810000e-01 -2.17769995e-01 -2.97560006e-01 -1.35100007e-01\n",
            "  5.98980010e-01  4.65290010e-01 -5.82579970e-01 -2.32299995e-02\n",
            " -1.54419994e+00  1.90099999e-02 -1.58769991e-02  2.44989991e-02\n",
            " -5.80169976e-01 -6.76590025e-01 -4.03789990e-02 -4.40429986e-01\n",
            "  8.32920000e-02  2.00350001e-01 -7.54989982e-01  1.69180006e-01\n",
            " -2.65729994e-01 -5.28779984e-01  1.75840005e-01  1.06500006e+00]\n",
            "Length of the vector for 'good': 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we displayed an example of how a vector of concatenated embeddings looks like, in this case for the word: good."
      ],
      "metadata": {
        "id": "NVw4Yz1NbuHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. LSTM model"
      ],
      "metadata": {
        "id": "yHGXDsoLcPYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6.1: Preparation of the Dataset\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, df, word_vectors, max_len=20):\n",
        "        self.df = df\n",
        "        self.word_vectors = word_vectors\n",
        "        # We set a max length of the reviews, they should be made of max 20 words otherwise there would be problems with shapes in input for the model,\n",
        "        # it can work because most of the reviews have less than 20 words.\n",
        "        self.max_len = max_len\n",
        "        # We incude tye padding in order to have the inputs, all of the same size\n",
        "        self.pad_vector = np.zeros(300)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx]['text']\n",
        "        rating = self.df.iloc[idx]['rating']\n",
        "\n",
        "        # Conversion of each review to list of embeddings, according to the scores contained in the dictionary word_vectors\n",
        "        # a list comprehension is used to iterate over the words in the text list\n",
        "        # For each word in the text, it checks if the word is present in the self.word_vectors dictionary\n",
        "        embeddings = [self.word_vectors[word] if word in self.word_vectors else self.pad_vector for word in text]\n",
        "\n",
        "        # In this code, all the reviews that don't respect the constraint of 20 words are truncated or padded\n",
        "        if len(embeddings) > self.max_len:\n",
        "            embeddings = embeddings[:self.max_len]\n",
        "        else:\n",
        "            embeddings.extend([self.pad_vector] * (self.max_len - len(embeddings))) # if the word is not found in the unique words vector, it is padded with all 0\n",
        "\n",
        "        embeddings = np.array(embeddings)\n",
        "\n",
        "        # The \"rating\" column is converted to 1 for positive (3, 4, 5), 0 for negative (1, 2)\n",
        "        label = 1 if rating in [3, 4, 5] else 0\n",
        "\n",
        "        return torch.tensor(embeddings, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "D_Dvr90BcUv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ReviewDataset(df, word_vectors)\n",
        "\n",
        "def print_sample_details(dataset, num_samples=5):\n",
        "    for i in range(num_samples):\n",
        "        embeddings, label = dataset[i]\n",
        "        print(f\"Sample {i}:\")\n",
        "        print(f\"Embeddings: {embeddings}\")\n",
        "        print(f\"Label: {label}\")\n",
        "        print(f\"Shape of embeddings: {embeddings.shape}\")\n",
        "        print()\n",
        "\n",
        "print_sample_details(dataset)"
      ],
      "metadata": {
        "id": "ZAWe3Bn0cltO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6.2: Creatig an LSTM Classifier\n",
        "class CustomLSTMClassifier(pl.LightningModule):\n",
        "    def __init__(self, input_dim=300, hidden_dim=128, output_dim=2, n_layers=3, bidirectional=False, dropout=0.2):\n",
        "    # input_dim: number of features in input, in outr case 300, that corresponds to the dimension of the vector for each word\n",
        "    # hidden_dim: = number of features in the hidden state\n",
        "    # output_dim: number of classes for classification\n",
        "    # n_layers: number of LSTM layers\n",
        "    # bidirectional: wheather the LSTM is bidirectional\n",
        "    # dropout: dropout rate for regularization\n",
        "        super(CustomLSTMClassifier, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # We define the weights and biases for the gates in the LSTM cell\n",
        "        # For the 'forget' gate\n",
        "        # torch.Tensor(input_dim + hidden_dim, hidden_dim): creates a tensor with dimensions 300+128, 128\n",
        "        # nn.Parameters(): wraps the tensor into a nn.Parameter object\n",
        "\n",
        "        # Forget gate\n",
        "        self.Wf = nn.Parameter(torch.Tensor(input_dim + hidden_dim, hidden_dim)) # forget weights\n",
        "        self.bf = nn.Parameter(torch.Tensor(hidden_dim)) # forget biases\n",
        "\n",
        "        # Input gate\n",
        "        self.Wi = nn.Parameter(torch.Tensor(input_dim + hidden_dim, hidden_dim)) # input gate weights\n",
        "        self.bi = nn.Parameter(torch.Tensor(hidden_dim)) # input gate biases\n",
        "\n",
        "        # Cell gate\n",
        "        self.Wc = nn.Parameter(torch.Tensor(input_dim + hidden_dim, hidden_dim)) # cell gate weights\n",
        "        self.bc = nn.Parameter(torch.Tensor(hidden_dim)) # cell gate biases\n",
        "\n",
        "        # Output gate\n",
        "        self.Wo = nn.Parameter(torch.Tensor(input_dim + hidden_dim, hidden_dim)) # ouput gate weights\n",
        "        self.bo = nn.Parameter(torch.Tensor(hidden_dim)) # output gate weights and biases\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "        # Metrics\n",
        "        self.accuracy = torchmetrics.Accuracy(task='binary', num_classes=output_dim)\n",
        "        self.precision = torchmetrics.Precision(task='binary', num_classes=output_dim, average='macro')\n",
        "        self.recall = torchmetrics.Recall(task='binary', num_classes=output_dim, average='macro')\n",
        "        self.f1 = torchmetrics.F1Score(task='binary', num_classes=output_dim, average='macro')\n",
        "\n",
        "    # A method is done to initialize the weights\n",
        "    def init_weights(self):\n",
        "        for param in self.parameters():\n",
        "            if param.dim() > 1:\n",
        "                nn.init.xavier_uniform_(param) # Xavier is used to initialise a parameter if this parameter is multi-dimensional\n",
        "            else:\n",
        "                param.data.fill_(0.0)\n",
        "\n",
        "    # The forward pass through the network is defined\n",
        "    def forward(self, x):\n",
        "        # We initiallize the hidden state\n",
        "        h_t = torch.zeros(x.size(0), self.hidden_dim, device=self.device)\n",
        "        # We initialize the cell state\n",
        "        c_t = torch.zeros(x.size(0), self.hidden_dim, device=self.device)\n",
        "\n",
        "        # the LSTM cell combines the input at the current time step with the previous hidden state to determne the new hidden state and cell state\n",
        "        for t in range(x.size(1)): # iterates over each time step in the sequence\n",
        "            x_t = x[:, t, :] # extracts the input at time step t for all elements in the batch\n",
        "            combined = torch.cat((x_t, h_t), dim=1) # concatenates the input at time t with the previous hidden state\n",
        "\n",
        "            f_t = torch.sigmoid(combined @ self.Wf + self.bf) # Forget state activation, matrix multiplication between combined and forget weights, then the forget biases are added\n",
        "            i_t = torch.sigmoid(combined @ self.Wi + self.bi) # input gate activation\n",
        "            g_t = torch.tanh(combined @ self.Wc + self.bc) # cell gate activation\n",
        "            o_t = torch.sigmoid(combined @ self.Wo + self.bo) # output gate activation\n",
        "\n",
        "            # New cell state and hidden state\n",
        "            c_t = f_t * c_t + i_t * g_t # updates the cell state by combining the previous cell state and the current cell gate value, modulated for the forget and input gates\n",
        "            h_t = o_t * torch.tanh(c_t) # updates the hidden state based on the new cell state and the output gate\n",
        "\n",
        "        output = self.fc(h_t)\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x) # performing the forward pass\n",
        "        loss = self.loss_fn(y_hat, y) # calculating the loss\n",
        "\n",
        "        y_prob = torch.softmax(y_hat, dim=1)\n",
        "        y_pred = torch.argmax(y_prob, dim=1)\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', self.accuracy(y_pred, y))\n",
        "        self.log('train_precision', self.precision(y_pred, y))\n",
        "        self.log('train_recall', self.recall(y_pred, y))\n",
        "        self.log('train_f1', self.f1(y_pred, y))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x)\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "\n",
        "        y_prob = torch.softmax(y_hat, dim=1)\n",
        "        y_pred = torch.argmax(y_prob, dim=1)\n",
        "\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', self.accuracy(y_pred, y), prog_bar=True)\n",
        "        self.log('val_precision', self.precision(y_pred, y), prog_bar=True)\n",
        "        self.log('val_recall', self.recall(y_pred, y), prog_bar=True)\n",
        "        self.log('val_f1', self.f1(y_pred, y), prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x)\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "\n",
        "        y_prob = torch.softmax(y_hat, dim=1)\n",
        "        y_pred = torch.argmax(y_prob, dim=1)\n",
        "\n",
        "        self.log('test_loss', loss, prog_bar=True)\n",
        "        self.log('test_acc', self.accuracy(y_pred, y), prog_bar=True)\n",
        "        self.log('test_precision', self.precision(y_pred, y), prog_bar=True)\n",
        "        self.log('test_recall', self.recall(y_pred, y), prog_bar=True)\n",
        "        self.log('test_f1', self.f1(y_pred, y), prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "adtibQGZcq4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training, validation, and test sets\n",
        "train_df, temp_df = train_test_split(df, test_size=0.4)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
        "\n",
        "# Creating datasets and dataloaders\n",
        "train_dataset = ReviewDataset(train_df, word_vectors)\n",
        "val_dataset = ReviewDataset(val_df, word_vectors)\n",
        "test_dataset = ReviewDataset(test_df, word_vectors)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "csv_logger = CSVLogger(\"logs\", name=\"my_model\")\n",
        "\n",
        "# Defining the custom model, checkpoint, and early stopping callbacks\n",
        "model = CustomLSTMClassifier()  # Using the custom LSTM classifier\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(monitor='val_loss', save_top_k=1, mode='min')\n",
        "early_stop_callback = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n",
        "\n",
        "# Creation of the trainer\n",
        "trainer = pl.Trainer(max_epochs=3, callbacks=[checkpoint_callback, early_stop_callback], logger=csv_logger)\n",
        "\n",
        "# Training of the model\n",
        "trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "# Testing the model\n",
        "trainer.test(model, test_loader)"
      ],
      "metadata": {
        "id": "E7gx1xgYcttb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6.4: Plot the Accuracy and Loss\n",
        "metrics = pd.read_csv(\"logs/my_model/version_0/metrics.csv\")\n",
        "\n",
        "epoch_metrics = metrics.groupby('epoch').mean()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epoch_metrics.index, epoch_metrics['train_acc'], label='Train Accuracy', marker='o')\n",
        "plt.plot(epoch_metrics.index, epoch_metrics['val_acc'], label='Validation Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(epoch_metrics.index)\n",
        "plt.legend()\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epoch_metrics.index, epoch_metrics['train_loss'], label='Train Loss', marker='o')\n",
        "plt.plot(epoch_metrics.index, epoch_metrics['val_loss'], label='Validation Loss', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(epoch_metrics.index)\n",
        "plt.legend()\n",
        "plt.title('Loss over Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AjSQHu2Scz_b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}